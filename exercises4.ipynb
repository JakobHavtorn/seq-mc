{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "T = 50\n",
    "C = 1\n",
    "Q = 1\n",
    "R = 1\n",
    "theta = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State space model\n",
    "\n",
    "def step_x(x, Q, **kwargs):\n",
    "    return np.cos(kwargs[\"theta\"] * x) + np.random.normal(0, np.sqrt(Q), size=x.shape)\n",
    "\n",
    "def step_y(x, C, R, **kwargs):\n",
    "    return C * x + np.random.normal(0, np.sqrt(R), size=x.shape)\n",
    "\n",
    "\n",
    "# # State space model\n",
    "\n",
    "# def step_x(x, Q, **kwargs):\n",
    "#     return kwargs[\"theta\"] * x + np.random.normal(0, np.sqrt(Q), size=x.shape)\n",
    "\n",
    "# def step_y(x, C, R, **kwargs):\n",
    "#     return C * x + np.random.normal(0, np.sqrt(R), size=x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate data\n",
    "\n",
    "def simulate_ssm(T, theta):\n",
    "    x = np.zeros(T + 1)\n",
    "    y = np.zeros(T + 1)\n",
    "    x[0] = np.random.normal(0, 1)\n",
    "    y[0] = x[0] + np.random.normal(0, 1)\n",
    "    for t in range(1, T + 1):\n",
    "        x[t] = step_x(x[t-1], Q, theta=theta)\n",
    "        y[t] = step_y(x[t], C, R, theta=theta)\n",
    "    return x[1:], y[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data, y_data = simulate_ssm(T, theta)\n",
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_data)\n",
    "plt.ylabel(\"$x_t$\")\n",
    "plt.xlabel(\"$t$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_data)\n",
    "plt.plot(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully Adapted Particle Filter (to estimate the likelihood z_hat = p(y_data|theta))\n",
    "\n",
    "def fully_adapted_pf(initial_particles, step_x, C, Q, R, seed=0, **step_kwargs):\n",
    "    \"\"\"Fully adapted particle filter for a nonlinear Gaussian State Space Model.\n",
    "\n",
    "    The importance weights are uniform for this PF.\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    N = len(initial_particles)\n",
    "    print(f\"Running with {N} particles\")\n",
    "    particles = [None] * T + [initial_particles]  # draw initial particles - put at index -1\n",
    "    nu_weights = [None] * T  # these are nu weights\n",
    "    mean_observation = [None] * T  # p(y_t|x_t)\n",
    "    std_observation = [None] * T\n",
    "    mean_state_prediction = [None] * T  # p(x_t|x_t-1)\n",
    "    std_state_prediction = [None] * T\n",
    "    mean_filtering = [None] * T  # p(x_t|x_t-1, y_t)\n",
    "    std_filtering = [None] * T\n",
    "    ancestor_indices = [None] * T\n",
    "    loglikelihood = 0\n",
    "\n",
    "    K = Q * C / (C * Q * C + R)\n",
    "    state_proposal_stddev = np.sqrt((1 - K * C) * Q)\n",
    "    obs_proposal_stddev = np.sqrt(C * Q * C + R)\n",
    "\n",
    "    for t in tqdm(range(T)):\n",
    "        # WEIGHT\n",
    "        # measurement\n",
    "        fcn = step_x(particles[t-1], Q, **step_kwargs)\n",
    "        obs_mean = C * fcn\n",
    "        measurement_proposal_dist = scipy.stats.norm(obs_mean, obs_proposal_stddev)  # p(y_t|x_t-1)\n",
    "\n",
    "        # compute weights (nu)\n",
    "        log_nu_weights_unnorm = measurement_proposal_dist.logpdf(y_data[t])\n",
    "        log_nu_weights_max = np.max(log_nu_weights_unnorm)\n",
    "        nu_weights_unnorm = np.exp(log_nu_weights_unnorm - log_nu_weights_max) + log_nu_weights_max\n",
    "        nu_weights[t] = nu_weights_unnorm / np.sum(nu_weights_unnorm)\n",
    "\n",
    "        # RESAMPLE\n",
    "        a_indices = np.random.choice(range(N), p=nu_weights[t], replace=True, size=N)\n",
    "        ancestor_indices[t] = a_indices\n",
    "\n",
    "        # PROPAGATE\n",
    "        # state\n",
    "        fcn = step_x(particles[t-1][a_indices], Q, **step_kwargs)\n",
    "        state_mean = fcn + K * (y_data[t] - C * fcn)\n",
    "        state_proposal_dist = scipy.stats.norm(state_mean, state_proposal_stddev)  # p(x_t|x_t-1^a_t,y_t)\n",
    "        particles[t] = state_proposal_dist.rvs()\n",
    "\n",
    "        # Store some statistics\n",
    "        # marginal filtering mean and variance\n",
    "        mean_filtering[t], std_filtering[t] = np.mean(particles[t]), np.std(particles[t])\n",
    "        # prediction\n",
    "        fcn = step_x(particles[t-1], Q, **step_kwargs)  # this is done before resampling\n",
    "        state_prediction_dist = scipy.stats.norm(fcn, np.sqrt(Q))  # p(x_t|x_t-1)\n",
    "        mean_state_prediction[t] = np.mean(state_prediction_dist.mean())\n",
    "        std_state_prediction[t] = np.mean(state_prediction_dist.std())\n",
    "        # measurement\n",
    "        measurement_dist = scipy.stats.norm(C * particles[t], np.sqrt(R))\n",
    "        mean_observation[t] = np.mean(measurement_dist.mean())\n",
    "        std_observation[t] = np.mean(measurement_dist.std())\n",
    "\n",
    "        # likelihood\n",
    "        log_obs = measurement_dist.logpdf(y_data[t])\n",
    "        log_state_prop = state_proposal_dist.logpdf(particles[t])\n",
    "        log_state_pred = state_prediction_dist.logpdf(particles[t])\n",
    "        loglikelihood += log_obs + log_state_pred - log_state_prop - log_nu_weights_unnorm - np.log(N)\n",
    "\n",
    "    nu_weights = np.array(nu_weights)\n",
    "    #particles = np.array(particles[-1:] + particles[1:-1])  # move initial particle to index 0  #  np.array(particles[:-1])\n",
    "    particles = np.array(particles[:-1])  # remove initial state\n",
    "    mean_filtering = np.array(mean_filtering)\n",
    "    std_filtering = np.array(std_filtering)\n",
    "    mean_state_prediction = np.array(mean_state_prediction)\n",
    "    std_state_prediction = np.array(std_state_prediction)\n",
    "    mean_observation = np.array(mean_observation)\n",
    "    std_observation = np.array(std_observation)\n",
    "    loglikelihood = np.array(loglikelihood)\n",
    "    ancestor_indices = np.array(ancestor_indices)\n",
    "\n",
    "    output = SimpleNamespace(\n",
    "        nu_weights=nu_weights, particles=particles, mean_filtering=mean_filtering,\n",
    "        std_filtering=std_filtering, mean_state_prediction=mean_state_prediction,\n",
    "        std_state_prediction=std_state_prediction, mean_observation=mean_observation,\n",
    "        std_observation=std_observation, loglikelihood=loglikelihood, ancestor_indices=ancestor_indices,\n",
    "    )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5000\n",
    "initial_particles = np.random.normal(0, 1, N)\n",
    "output = fully_adapted_pf(initial_particles, step_x, C, Q, R, seed=0, theta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(x_data - output.mean_filtering)), np.mean(x_data - output.mean_filtering), np.var(x_data - output.mean_filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_data - output.mean_filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_data)\n",
    "plt.plot(output.mean_filtering);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(output.std_filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate parameters (infer posterior p(theta|y_data)) using Particle Metropolis Hastings\n",
    "theta_prior = scipy.stats.norm(0, 1)  # p(theta) = N(0, 1)\n",
    "theta_rw_proposal = scipy.stats.norm(0, 0.1)  # q(theta'|theta) = N(0, 0.1)\n",
    "M = 100  # Number of PMH runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def particle_metropolis_hastings(initial_theta, random_walk_proposal, step_x, C, Q, R, seed=seed):\n",
    "    np.random.seed(seed)\n",
    "    theta = initial_theta\n",
    "    for m in range(M):\n",
    "        theta = theta + random_walk_proposal.rvs()\n",
    "        output = fully_adapted_pf(initial_particles, step_x, C, Q, R, seed=None, theta=theta)\n",
    "        acceptance_ratio = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_theta = 0.5  # theta_prior.rvs()\n",
    "particle_metropolis_hastings(initial_theta, theta_rw_proposal, step_x, C, Q, R, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad1047fe110e6526ec8270bc6abda2b9b08acd2c82835ba9522086c3ef7bec77"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('seq-mc': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
