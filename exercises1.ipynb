{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "\n",
    "proposal = scipy.stats.norm(0, 1)\n",
    "target = scipy.stats.uniform(0, 4)\n",
    "\n",
    "samples = proposal.rvs(size=N)\n",
    "weights = target.pdf(samples) / proposal.pdf(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(samples, bins=100, weights=weights);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proposal is poor with very low densities toward x > 3 and too high density for x < 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "\n",
    "proposal = scipy.stats.norm(2, 1)\n",
    "target = scipy.stats.uniform(0, 4)\n",
    "\n",
    "samples = proposal.rvs(size=N)\n",
    "weights = target.pdf(samples) / proposal.pdf(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(samples, bins=100, weights=weights);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "\n",
    "proposal = scipy.stats.norm(2, 1)\n",
    "target = scipy.stats.uniform(0, 4)\n",
    "\n",
    "samples = proposal.rvs(size=N)\n",
    "weights = target.pdf(samples) / proposal.pdf(samples)\n",
    "\n",
    "np.mean(weights * samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal = scipy.stats.norm(2, 1)\n",
    "target = scipy.stats.uniform(0, 4)\n",
    "\n",
    "all_N = list(range(10, 10000, 10))\n",
    "all_weights = []\n",
    "for N in all_N:\n",
    "    samples = proposal.rvs(size=N)\n",
    "    weights = target.pdf(samples) / proposal.pdf(samples)\n",
    "    all_weights.append(np.mean(weights * samples))\n",
    "\n",
    "plt.plot(all_N, all_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\widehat{Z} &= \\int \\tilde{\\pi}(x) dx \\\\\n",
    "&= \\int q(x)\\frac{\\tilde{\\pi}(x)}{q(x)} dx \\\\\n",
    "&= \\mathbb{E}_q \\left[ \\frac{\\tilde{\\pi}(x)}{q(x)} \\right] \\\\\n",
    "&\\approx \\frac{1}{N} \\sum_{i=1}^N \\frac{\\tilde{\\pi}(x^i)}{q(x^i)} \\\\\n",
    "&\\approx \\frac{1}{N} \\sum_{i=1}^N \\tilde{W}^i \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "\n",
    "def target_unnorm(x, a=0, b=4):\n",
    "    out = np.zeros_like(x)\n",
    "    idx = (a <= x) * (x <= b)\n",
    "    out[idx] = 1\n",
    "    if out.ndim == 2:\n",
    "        out = (out.sum(axis=1) > 0).astype(np.float)\n",
    "    elif out.ndim > 2:\n",
    "        raise ValueError(\"Dimension > 2\")\n",
    "    return out\n",
    "\n",
    "proposal = scipy.stats.norm(0, 1)\n",
    "proposal = scipy.stats.norm(2, 1)\n",
    "proposal = scipy.stats.uniform(0, 4)\n",
    "\n",
    "samples = proposal.rvs(size=N)\n",
    "weights_unnorm = target_unnorm(samples) / proposal.pdf(samples)\n",
    "\n",
    "np.mean(weights_unnorm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proposal = scipy.stats.norm(0, 1)\n",
    "proposal = scipy.stats.norm(2, 1)\n",
    "#proposal = scipy.stats.uniform(0, 4)\n",
    "\n",
    "all_N = list(range(10, 10000, 10))\n",
    "all_weights = []\n",
    "for N in all_N:\n",
    "    samples = proposal.rvs(size=N)\n",
    "    weights_unnorm = target_unnorm(samples) / proposal.pdf(samples)\n",
    "    all_weights.append(np.mean(weights_unnorm))\n",
    "\n",
    "plt.plot(all_N, all_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is self-normalized importance sampling. We normalize the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal = scipy.stats.norm(0, 3)\n",
    "\n",
    "all_N = list(range(1, 1000, 1))\n",
    "all_est = []\n",
    "for N in all_N:\n",
    "    samples = proposal.rvs(size=N)\n",
    "    weights_unnorm = target_unnorm(samples) / proposal.pdf(samples)\n",
    "    Z_hat = np.mean(weights_unnorm)\n",
    "    varphi = np.mean(weights_unnorm * samples) / Z_hat\n",
    "    all_est.append(varphi)\n",
    "\n",
    "plt.plot(all_N, all_est)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing that the self-normalized importance sampler is biased (with an assymmetric proposal)\n",
    "\n",
    "proposal = scipy.stats.norm(0, 3)\n",
    "\n",
    "all_N = list(range(1, 100))\n",
    "all_est = []\n",
    "for N in tqdm(all_N):\n",
    "    tmp_est = []\n",
    "    for r in range(1000):\n",
    "        samples = proposal.rvs(size=N)\n",
    "        weights_unnorm = target_unnorm(samples) / proposal.pdf(samples)\n",
    "        Z_hat = np.mean(weights_unnorm)\n",
    "        varphi = np.mean(weights_unnorm * samples) / Z_hat\n",
    "        tmp_est.append(varphi)\n",
    "    \n",
    "    all_est.append(np.mean(tmp_est))  # mean of MC estimates (to remove MC estimate variance)\n",
    "\n",
    "plt.plot(all_N, all_est)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more efficient/direct way of computing\n",
    "\n",
    "proposal = scipy.stats.norm(0, 3)\n",
    "\n",
    "all_N = list(range(1, 1000, 1))\n",
    "all_est = []\n",
    "for N in all_N:\n",
    "    samples = proposal.rvs(size=N)\n",
    "    weights_unnorm = target_unnorm(samples) / proposal.pdf(samples)\n",
    "    weights = weights_unnorm / np.sum(weights_unnorm)\n",
    "    varphi = np.sum(weights * samples)\n",
    "    all_est.append(varphi)\n",
    "\n",
    "plt.plot(all_N, all_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "\n",
    "def multivariate_uniform_pdf(x, a=-0.5, b=0.5):\n",
    "    target = scipy.stats.uniform(a, b)\n",
    "    pdf = list(np.prod(target.pdf(x_)) for x_ in x)  # (N, D)\n",
    "    return pdf\n",
    "\n",
    "all_weights = []\n",
    "n_nonzero_weights = []\n",
    "\n",
    "dims = list(range(1, 10, 1))\n",
    "for d in tqdm(dims):\n",
    "    proposal = scipy.stats.multivariate_normal([0] * d, 1)\n",
    "    samples = proposal.rvs(size=N)\n",
    "    weights = multivariate_uniform_pdf(samples) / proposal.pdf(samples)\n",
    "\n",
    "    all_weights.append(weights)\n",
    "\n",
    "    n_nonzero_weights.append(np.sum(weights > 0) / N)\n",
    "\n",
    "plt.plot(dims, n_nonzero_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will get NaN weights because the weights become so close to zero that they cannot be represented as different from zero in the given floating point precision. We then divide by 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "d = 100\n",
    "\n",
    "\n",
    "def target_unnorm(x, a=0, b=4):\n",
    "    out = np.zeros_like(x)\n",
    "    idx = (a <= x) * (x <= b)\n",
    "    out[idx] = 1\n",
    "    if out.ndim == 2:\n",
    "        out = np.prod(out, axis=1)  # hypercube\n",
    "    elif out.ndim > 2:\n",
    "        raise ValueError(\"Dimension > 2\")\n",
    "    return out\n",
    "\n",
    "\n",
    "all_weights = []\n",
    "n_nonzero_weights = []\n",
    "\n",
    "proposal = scipy.stats.multivariate_normal([2] * d, 1)\n",
    "samples = proposal.rvs(size=N)\n",
    "log_weights_unnorm = target_unnorm(samples) - proposal.logpdf(samples)\n",
    "weights_unnorm = np.exp(log_weights_unnorm)\n",
    "weights = weights_unnorm / np.sum(weights_unnorm)\n",
    "\n",
    "np.sum(weights[:, np.newaxis] * samples, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "d = 1000\n",
    "\n",
    "all_weights = []\n",
    "n_nonzero_weights = []\n",
    "\n",
    "proposal = scipy.stats.multivariate_normal([2] * d, 1)\n",
    "samples = proposal.rvs(size=N)\n",
    "log_weights_unnorm = target_unnorm(samples) - proposal.logpdf(samples)\n",
    "weights = np.exp(log_weights_unnorm - np.max(log_weights_unnorm))\n",
    "\n",
    "np.sum(weights[:, np.newaxis] * samples, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This final approach has good numerical stability and is valid since subtraction in log space is equivalent to division in real space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate the marginal ﬁltering distribution at each time index t = 1, . . . , T using the bootstrap particle ﬁlter with N = 500 particles\n",
    "\n",
    "$p(x_t| y_{1:t})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_data = pd.read_csv(\"./seOMXlogreturns2012to2014.csv\")\n",
    "T = observation_data.shape[0]\n",
    "observation_data = observation_data.to_numpy()[:, 0]\n",
    "observation_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = 0.98\n",
    "sigma = 0.16\n",
    "beta = 0.70\n",
    "\n",
    "N = 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap Particle Filter\n",
    "initial_particle_dist = scipy.stats.norm(0, 1)\n",
    "weights = [np.array([1/N] * N)] + [None] * T\n",
    "particles = [initial_particle_dist.rvs(N)] + [None] * T  # draw initial particles\n",
    "mean_observation = [None] * T\n",
    "prediction = [None] * T\n",
    "marginal_filtering = [None] * T\n",
    "\n",
    "for t in tqdm(range(T)):\n",
    "    # RESAMPLE\n",
    "    ancestor_indices = np.random.choice(range(N), p=weights[t], replace=True, size=N)\n",
    "\n",
    "    # PROPAGATE\n",
    "    # state\n",
    "    proposal_dist = scipy.stats.norm(phi * particles[t][ancestor_indices], sigma)\n",
    "    particles[t+1] = proposal_dist.rvs()\n",
    "\n",
    "    # measurement\n",
    "    measurement_dist = scipy.stats.norm(0, np.sqrt(beta ** 2 * np.exp(particles[t+1])))\n",
    "    # mean observation\n",
    "    mean_observation[t] = scipy.stats.norm(0, np.sqrt(beta ** 2 * np.exp(np.mean(particles[t+1])))).rvs()\n",
    "\n",
    "    # WEIGHT\n",
    "    weights[t+1] = measurement_dist.logpdf(observation_data[t])\n",
    "    weights[t+1] = np.exp(weights[t+1] - np.max(weights[t+1]))\n",
    "    weights[t+1] = weights[t+1] / np.sum(weights[t+1])\n",
    "\n",
    "    prediction[t] = np.mean(particles[t])\n",
    "    marginal_filtering[t] = np.sum(weights[t] * particles[t])\n",
    "\n",
    "weights = np.array(weights[:-1])\n",
    "particles = np.array(particles[:-1])\n",
    "mean_observation = np.array(mean_observation)\n",
    "prediction = np.array(prediction)\n",
    "marginal_filtering = np.array(marginal_filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_particle = np.mean(particles, axis=1)\n",
    "weighted_particle = np.sum(weights * particles, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Prediction\")\n",
    "plt.plot(observation_data)\n",
    "plt.plot(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Marginal filtering\")\n",
    "plt.plot(observation_data)\n",
    "plt.plot(marginal_filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Mean observation\")\n",
    "plt.plot(observation_data)\n",
    "plt.plot(mean_observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad1047fe110e6526ec8270bc6abda2b9b08acd2c82835ba9522086c3ef7bec77"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('seq-mc': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
